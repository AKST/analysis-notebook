// Vitest Snapshot v1, https://vitest.dev/guide/snapshot.html

exports[`app(unsw::2206::05.1).widgets > aSingleDummyIndependentVariable 1`] = `
"<div class="container pre--container"><div style="display: grid; grid-template-columns: 1fr auto;"><h2>A Single Dummy Independent Variable</h2><span style="display: grid; grid-auto-flow: column; align-items: center; max-height: 2em; line-height: 1; font-size: 10px; color: var(--fg-black-on-pink); background: var(--bg-pink); padding: 4px;"><strong>Book (C7 P222)</strong></span></div><div class="container dashbox" style="padding: 16px; border: var(--border-white-dash);"><div class="c2 twoThree pre--c2 pre--two-three"><div class="container pre--container"><ul style="margin-block: 0px;"><li>When you have a single Categorical and quantative variable<ul class="no-item-padding" style="margin-block: 0px;"><li>The Categorical variable acts as intercept shift</li></ul></li></ul><figure class="pre--horizontal-shadow"><math display="block"><mtable><mtr columnalign=""><mtd columnalign=""><mtd><mrow><mi>y</mi><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤</mi><mn>0</mn></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ¥</mi><mn>0</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mi>dummy</mi></mrow><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mi>u</mi></mrow></mrow></mtd></mtd></mtr><mtr columnalign=""><mtd columnalign=""><mtd><mtable style="font-size: 12px"><mtr columnalign="right center left"><mtd columnalign="right"><mrow><mi>E</mi><mrow><mo>(</mo><mrow><mi>y</mi><mspace width="2px"></mspace><mo>|</mo><mspace width="2px"></mspace><mrow><mi>dummy</mi><mo>=</mo><mn>0</mn></mrow></mrow><mo>)</mo></mrow></mrow></mtd><mtd columnalign="center"><mo>=</mo></mtd><mtd columnalign="left"><msub><mi>Œ≤</mi><mn>0</mn></msub></mtd></mtr><mtr columnalign="right center left"><mtd columnalign="right"><mrow><mi>E</mi><mrow><mo>(</mo><mrow><mi>y</mi><mspace width="2px"></mspace><mo>|</mo><mspace width="2px"></mspace><mrow><mi>dummy</mi><mo>=</mo><mn>1</mn></mrow></mrow><mo>)</mo></mrow></mrow></mtd><mtd columnalign="center"><mo>=</mo></mtd><mtd columnalign="left"><mrow><msub><mi>Œ≤</mi><mn>0</mn></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><msub><mi>Œ¥</mi><mn>0</mn></msub></mrow></mtd></mtr><mtr columnalign="right center left"><mtd columnalign="right"><mrow><mrow><mi>E</mi><mrow><mo>(</mo><mrow><mi>y</mi><mspace width="2px"></mspace><mo>|</mo><mspace width="2px"></mspace><mrow><mi>dummy</mi><mo>=</mo><mn>1</mn></mrow></mrow><mo>)</mo></mrow></mrow><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mrow><mi>E</mi><mrow><mo>(</mo><mrow><mi>y</mi><mspace width="2px"></mspace><mo>|</mo><mspace width="2px"></mspace><mrow><mi>dummy</mi><mo>=</mo><mn>0</mn></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mtd><mtd columnalign="center"><mo>=</mo></mtd><mtd columnalign="left"><msub><mi>Œ¥</mi><mn>0</mn></msub></mtd></mtr></mtable></mtd></mtd></mtr></mtable></math><figcaption>Effects of dummy variables</figcaption></figure><p>
          <strong>Œ¥‚ÇÄ</strong> represents the mean difference in the
          absense of presence of a dummy. A less abstract example
          might be the difference between man and women if the
          dummy was gender.
        </p><div style="display: grid; grid-template-columns: 1fr auto;"><h4>Interpretation Coefficients with (log(y))</h4><span style="display: grid; grid-auto-flow: column; align-items: center; max-height: 2em; line-height: 1; font-size: 10px; color: var(--fg-black-on-pink); background: var(--bg-pink); padding: 4px;"><strong>Book (C7 P226)</strong></span></div><ul style="margin-block: 0px;"><li>Coefficients have a percentage interpretation<ul style="margin-block: 0px;"><li>
              Holding all other factors Fixed, the coefficient on a dummy
              variable can be interpretded as a % difference (when multiplying
              by 100).
            </li><li>
              When the coefficient on a dummy variable suggests a large
              proportionate change in the dependent variable, the exact
              % difference can be obtained exactly as with the
              semi-elasticity calculation. <figure class="pre--horizontal-shadow"><math display="block"><mrow><mn>100</mn><mspace width="1px"></mspace><mo>¬∑</mo><mspace width="1px"></mspace><mrow><mo>[</mo><mrow><mtext>Exp</mtext><mspace width="2px"></mspace><mrow><mo>(</mo><msub><mi>Œ≤ÃÇ</mi><mn>1</mn></msub><mo>)</mo></mrow></mrow><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mn>1</mn><mo>]</mo></mrow></mrow></math><figcaption>Semi Elasitic Calculation</figcaption></figure>
            </li></ul></li></ul></div><dl><dt>Intercept Shift</dt><dd>
          The effect of the represense of a dummy variable and
          the value of its coefficient.
        </dd><dt>Dummy Variable Trap</dt><dd>
          Arises when too many dummy variables describe a given
          number of groups. A simple case of this is including
          both state of a categorical variable.
        </dd><dt>Base Group</dt><dd>
          This is the state of a binary variable baked into
          the intercept and not explictly specified as a
          variable.
        </dd></dl></div></div></div>"
`;

exports[`app(unsw::2206::05.1).widgets > binaryDependentVariable 1`] = `
"<div class="container pre--container"><h2>A Binary Dependent Variable: The Linear Probability Model</h2><div class="container dashbox" style="padding: 16px; border: var(--border-white-dash);"><blockquote>You may want to do this if you want to explain a <strong>Qualitative event</strong>.</blockquote><div class="c2 twoThree pre--c2 pre--two-three"><div class="container pre--container"><p>
          <strong>When the <em>dependent variable</em> of a model is a <strong>qualative
          variable</strong>, it takes on <em>only 2 values</em>, being <strong>zero</strong> or
          <strong>one</strong></strong>. One Interpretation of this is the model output acts as
          likilhood of an event occuring while the the inputs are the conditions
          (or determinants) for the probability, like in Conditional probability.
        </p><figure class="pre--horizontal-shadow"><math display="block"><mtable><mtr columnalign="right center left"><mtd columnalign="right"><mi>y</mi></mtd><mtd columnalign="center"><mo>=</mo></mtd><mtd columnalign="left"><mrow><msub><mi>Œ≤</mi><mn>0</mn></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>x</mi><mn>1</mn></msub></mrow><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mo>‚ãØ</mo><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mrow><mrow><msub><mi>Œ≤</mi><mi>k</mi></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>x</mi><mi>k</mi></msub></mrow><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mi>u</mi></mrow></mrow></mtd></mtr><mtr columnalign="right center left"><mtd columnalign="right"><mrow><mi>E</mi><mrow><mo>(</mo><mrow><mi>y</mi><mo>|</mo><mi>x</mi></mrow><mo>)</mo></mrow></mrow></mtd><mtd columnalign="center"><mo>=</mo></mtd><mtd columnalign="left"><mrow><msub><mi>Œ≤</mi><mn>0</mn></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>x</mi><mn>1</mn></msub></mrow><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mo>‚ãØ</mo><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤</mi><mi>k</mi></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>x</mi><mi>k</mi></msub></mrow></mrow></mtd></mtr><mtr columnalign="right center left"><mtd columnalign="right"><mrow><mi>P</mi><mrow><mo>(</mo><mrow><mi>y</mi><mo>=</mo><mn>1</mn><mo>|</mo><mi>x</mi></mrow><mo>)</mo></mrow></mrow></mtd><mtd columnalign="center"><mo>=</mo></mtd><mtd columnalign="left"><mrow><msub><mi>Œ≤</mi><mn>0</mn></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>x</mi><mn>1</mn></msub></mrow><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mo>‚ãØ</mo><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤</mi><mi>k</mi></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>x</mi><mi>k</mi></msub></mrow></mrow></mtd></mtr></mtable></math><figcaption>Conditional probability</figcaption></figure><p>
          Given the possible values for the dependent value is 1 or 0, the
          <strong><strong>Coefficients</strong> cannot be interpreted as a one unit
          change in <em>x<sub>j</sub></em> in the value of <em>y</em></strong>.
        </p><figure class="pre--horizontal-shadow"><math display="block"><mrow><mrow><mi>Œî</mi><mi>P</mi><mrow><mo>(</mo><mrow><mi>y</mi><mo>=</mo><mn>1</mn><mo>|</mo><mi>x</mi></mrow><mo>)</mo></mrow></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><munder><mrow><mrow><mi>Œî</mi><msub><mi>x</mi><mi>j</mi></msub></mrow></mrow><munder><mo>‚èü</mo><mrow style=""><mrow></mrow></mrow></munder></munder></mrow></mrow></math><figcaption>LPM coefficient interpretation</figcaption></figure><p>
          Given all this, we can continue to write our models
          as before, but this is something to keep in mind with
          interpretating the models outputs, and coefficients.
          Another thing to keep in mind <strong>with correctly
          interpreting a linear probability model, we must know
          what <em>constitutes</em> a <strong>‚Äúsuccess‚Äù</strong></strong>.
          It also helps to give the dependent variable a name
          that describes an event occuring.
        </p><blockquote>
          To interpret the estimates, we must remember that a
          change in the independent variable changes the
          probability that <strong>y = 1</strong>. These models are
          fairly easy to estimate and interpret.
        </blockquote></div><dl><dt>Conditional Probability</dt><dd><blockquote>
          ... <a href="https://en.wikipedia.org/wiki/Conditional_probability" target="_blank">Conditional Probability</a>
          is a measure of the probability of an event occurring, given
          that another event (by assumption, presumption, assertion or
          evidence) is already known to have occurred.
          [<cite><strong>wikipedia, 2025-10-23</strong></cite>]
        </blockquote></dd><dt>Linear probability model (LPM)</dt><dd>
          A linear regression model (multiple or singular)
          where the response value is the probablity.
        </dd><dt>Response Probablility</dt><dd>
          The response value of the a linear probablity model.
        </dd><dt>Quantative Variable</dt><dd>
          A variable that can be measured in continious
          or in discrete unit, but exists in terms of
          quantities.
        </dd><dt>Qualitative Variable</dt><dd>
          A variable that describes a quality of a
          characteristic which cannot be directly measured
          as a qunatity. Qualitative values can be ordinal
          with a natural ordering (e.g. properties with by
          number of bedrooms), and it can be without a
          natural ordering.
        </dd></dl></div><h4>Short comings of these models</h4><p>
      Even with these problems, the linear probability model is
      useful and often applied in economics, but they are worth
      noting to understand their limitations:
    </p><div class="c2 twoThree pre--c2 pre--two-three"><ul style="margin-block: 0px;"><li>
          <strong>We can get predictions either less than zero or greater than one</strong>:
          This is unideal as these are predicted probabilities, and probabilities must be between zero and one.
        </li><li>
          A related problem is that a probability cannot be linearly related to the
          independent variables for all their possible values.
        </li><li>
          LPM works well for values of the independent variables that are near the
          averages of the sample (Outliers from small samples will get extreme %'s).<ul class="no-item-padding" style="margin-block: 0px;"><li>
                One such example is employability of women in the workforce, when 96%
                women have have zero or one child (in a sample at least), the effect of
                children may be over pronounced for anyone with 2 or more.
              </li></ul>
        </li></ul><dl><dt>Precent correctly Predicted</dt><dd>
          Let yÃÇ·µ¢ denote the fitted values‚Äîwhich may not be bounded between zero
          and one. Define a predicted value as <strong><strong>yÃÉ·µ¢ = 1 if yÃÇ·µ¢ ‚â• .5 and yÃÉ·µ¢ &lt; .5</strong></strong>.
          Now we have a set of predicted values, <strong><strong>yÃÉ·µ¢ = { 1, ..., n }</strong></strong>
          that, like the yi, are either zero or one.
          <br><br>

          We can use the data on <strong>y·µ¢ = 1 and y·µ¢ = 0</strong> as the proportion
          of overall correct predictions.
        </dd></dl></div><p>
      Due to the binary nature of y, the linear probability model does violate
      one of the Gauss-Markov assumptions. <strong>When y is a binary variable,
      its variance, conditional on x</strong>, is:
      <br><figure class="pre--horizontal-shadow"><math display="block"><mrow><mrow><mtext>Var</mtext><mspace width="2px"></mspace><mrow><mo>(</mo><mrow><mi>y</mi><mspace width="2px"></mspace><mo>|</mo><mspace width="2px"></mspace><mi>x</mi></mrow><mo>)</mo></mrow></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><mrow><mi>p</mi><mspace width="2px"></mspace><mrow><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mrow><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mrow><mo>[</mo><mn>1</mn><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mrow><mi>p</mi><mspace width="2px"></mspace><mrow><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mrow><mo>]</mo></mrow></mrow></mrow></math><figcaption>LPM assumption violation</figcaption></figure><br>
      The implication is <strong>heteroskedasticity</strong>.
    </p></div></div>"
`;

exports[`app(unsw::2206::05.1).widgets > describingQualitativeInformation 1`] = `
"<div class="container pre--container"><div style="display: grid; grid-template-columns: 1fr auto;"><h2>Describing Qualitative Information</h2><span style="display: grid; grid-auto-flow: column; align-items: center; max-height: 2em; line-height: 1; font-size: 10px; color: var(--fg-black-on-pink); background: var(--bg-pink); padding: 4px;"><strong>Book (C7 P221)</strong></span></div><div class="container dashbox" style="padding: 16px; border: var(--border-white-dash);"><div class="c2 twoThree pre--c2 pre--two-three"><div class="container pre--container"><ul style="margin-block: 0px;"><li>
            When we put a binary categorical variable in a model, we
            often decide which one is explictly specified as a parameter
            as the effects of the omitted one gets baked into the
            intercept. Specifying both causes multicolinary problems.
          </li></ul></div><dl><dt>Dummy Variable</dt><dd>
          A binary variable, which is either zero or 1, it is used to
          demark the different qualitative states of a category variable.
        </dd></dl></div></div></div>"
`;

exports[`app(unsw::2206::05.1).widgets > dummyInteractions 1`] = `
"<div class="container pre--container"><div style="display: grid; grid-template-columns: 1fr auto;"><h2>Interactions Involving Dummy Variables</h2><span style="display: grid; grid-auto-flow: column; align-items: center; max-height: 2em; line-height: 1; font-size: 10px; color: var(--fg-black-on-pink); background: var(--bg-pink); padding: 4px;"><strong>Book (C7 P232)</strong></span></div><div class="container dashbox" style="padding: 16px; border: var(--border-white-dash);"><div class="c2 twoThree pre--c2 pre--two-three"><div class="container pre--container"><p>
          Having interactions between multiple dumies is basically the
          same as creating seperate permutations for each dummy.
        </p><h4>Allowing for different slopes</h4><figure class="pre--horizontal-shadow"><math display="block"><mrow><mi>y</mi><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤ÃÇ</mi><mn>0</mn></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><munder><mrow><msub><mi>Œ≤ÃÇ</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>x</mi><mn>1</mn></msub></mrow><mtext>dummy</mtext></munder><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><munder><mrow><msub><mi>Œ≤ÃÇ</mi><mn>2</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>x</mi><mn>2</mn></msub></mrow><mtext>slope</mtext></munder><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><munder><mrow><msub><mi>Œ≤ÃÇ</mi><mn>3</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>x</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>x</mi><mn>2</mn></msub></mrow><mtext>interaction</mtext></munder><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mi>u</mi></mrow></mrow><figcaption>Different slopes for dummy</figcaption></math></figure><p>
          Interaction terms allow you to measure a seperate slope for
          a quantitative variable for different dummy variables,
          like in the example above with a single dummy and slope.
          You would test it like this.
        </p><figure class="pre--horizontal-shadow"><math display="block"><mtable><mtr columnalign=""><mtd columnalign=""><mtd><mrow><mi>y</mi><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤</mi><mn>0</mn></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><munder><mrow><msub><mi>Œ¥</mi><mn>0</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>x</mi><mn>1</mn></msub></mrow><mtext>dummy</mtext></munder><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><munder><mrow><msub><mi>Œ≤</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>x</mi><mn>2</mn></msub></mrow><mtext>slope</mtext></munder><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><munder><mrow><msub><mi>Œ¥</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>x</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>x</mi><mn>2</mn></msub></mrow><mtext>interaction</mtext></munder><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mi>u</mi></mrow></mrow></mtd></mtd></mtr><mtr columnalign=""><mtd columnalign=""><mtd><mtable><mtr columnalign="left left"><mtd columnalign="left"><mrow><msub><mi>H</mi><mn>0</mn></msub><mo>:</mo></mrow></mtd><mtd columnalign="left"><mrow><msub><mi>Œ¥</mi><mn>0</mn></msub><mo>=</mo><msub><mi>Œ¥</mi><mn>1</mn></msub><mo>=</mo><mn>0</mn></mrow></mtd></mtr><mtr columnalign="left left"><mtd columnalign="left"><mrow><msub><mi>H</mi><mn>1</mn></msub><mo>:</mo></mrow></mtd><mtd columnalign="left"><mtext>otherwise</mtext></mtd></mtr></mtable></mtd></mtd></mtr></mtable></math><figcaption>F Test: Hypothesis test for different slopes</figcaption></figure><h4>Testing for differences in regression functions across groups</h4><div style="--fontsize-math-m: 14px;"><figure class="pre--horizontal-shadow"><math display="block"><mrow><mi>y</mi><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤ÃÇ</mi><mn>0</mn></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><munder><mrow><msub><mi>Œ≤ÃÇ</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>s</mi><mn>1</mn></msub></mrow><mtext>slope 1</mtext></munder><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><munder><mrow><msub><mi>Œ≤ÃÇ</mi><mn>2</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>s</mi><mn>2</mn></msub></mrow><mtext>slope 2</mtext></munder><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><munder><mrow><msub><mi>Œ≤ÃÇ</mi><mn>3</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>s</mi><mn>3</mn></msub></mrow><mtext>slope 3</mtext></munder><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mi>u</mi></mrow></mrow></math><figcaption>Model without dummy</figcaption></figure></div><p>
          Say you have have model which measure the effect of 3
          different slopes over a population, but then you realise
          that the slope varies between two different groups in
          these slopes. A simple example might be gender, but it
          could be anything so you update it to the following.
        </p><div style="--fontsize-math-m: 14px;"><figure class="pre--horizontal-shadow"><math display="block"><mtable><mtr columnalign="right center left"><mtd columnalign="right"><mi>y</mi></mtd><mtd columnalign="center"><mo>=</mo></mtd><mtd columnalign="left"><mrow><munder><mrow><msub><mi>Œ¥</mi><mn>0</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>d</mi><mn>1</mn></msub></mrow><mtext>dummy</mtext></munder><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><munder><mrow><msub><mi>Œ≤</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>s</mi><mn>1</mn></msub></mrow><mtext>slope 1</mtext></munder><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><munder><mrow><msub><mi>Œ¥</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>d</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>s</mi><mn>1</mn></msub></mrow><mtext>interaction</mtext></munder><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><munder><mrow><msub><mi>Œ≤</mi><mn>2</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>s</mi><mn>2</mn></msub></mrow><mtext>slope 2</mtext></munder><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mspace width="0px"></mspace></mrow></mtd></mtr><mtr columnalign="right center left"><mtd columnalign="right"><mspace width="0px"></mspace></mtd><mtd columnalign="center"><mspace width="0px"></mspace></mtd><mtd columnalign="left"><mrow><munder><mrow><msub><mi>Œ¥</mi><mn>2</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>d</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>s</mi><mn>2</mn></msub></mrow><mtext>interaction</mtext></munder><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><munder><mrow><msub><mi>Œ≤</mi><mn>3</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>s</mi><mn>3</mn></msub></mrow><mtext>slope 3</mtext></munder><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><munder><mrow><msub><mi>Œ¥</mi><mn>3</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>d</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>s</mi><mn>3</mn></msub></mrow><mtext>interaction</mtext></munder><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mi>u</mi></mrow></mtd></mtr></mtable></math><figcaption>Model with dummy</figcaption></figure></div><p>
          The difference in slope for under the dummy here
          are demarked with <strong>Œ¥</strong>. Generally speaking
          you would define a test like so with just the
          coefficents for the dummy, which again are
          demarked by the <strong>Œ¥</strong>.
        </p><figure class="pre--horizontal-shadow"><math display="block"><mrow><msub><mi>H</mi><mn>0</mn></msub><mo>:</mo><mspace width="4px"></mspace><mrow><mrow><msub><mi>Œ¥</mi><mn>0</mn></msub><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mn>0</mn></mrow><mspace width="0px"></mspace><mrow><mo>,</mo><mspace width="2px"></mspace></mrow><mspace width="0px"></mspace><mrow><msub><mi>Œ¥</mi><mn>1</mn></msub><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mn>0</mn></mrow><mspace width="0px"></mspace><mrow><mo>,</mo><mspace width="2px"></mspace></mrow><mspace width="0px"></mspace><mrow><msub><mi>Œ¥</mi><mn>2</mn></msub><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mn>0</mn></mrow><mspace width="0px"></mspace><mrow><mo>,</mo><mspace width="2px"></mspace></mrow><mspace width="0px"></mspace><mrow><msub><mi>Œ¥</mi><mn>3</mn></msub><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mn>0</mn></mrow></mrow></mrow></math><figcaption>Null hypothesis</figcaption></figure><p>
          If you tested the 4 terms independently none would have
          a very statistically significant t statistic. But this is
          a joint hypothesis so we need to instead compute out an
          F statistic. In this case our restricted model just drops
          all variables with the dummy (including interactions with it).
          From there we compute the a seperate R¬≤ and restricted R¬≤.
        </p><h4>Chow Test Approach</h4><p>
          Another way to test difference in slopes in groups is
          to instead split the data into different groups, which
          we denote with <strong>g</strong>. You will have a seperate group
          for each possible state of the dummy variable in quetsion.
          We can describe this group specific model like this:
        </p><div style="--fontsize-math-m: 14px;"><figure class="pre--horizontal-shadow"><math display="block"><mrow><msub><mi>y</mi><mi>g</mi></msub><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤ÃÇ</mi><mrow><mi>g</mi><mrow><mo>,</mo><mspace width="2px"></mspace></mrow><mn>0</mn></mrow></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤ÃÇ</mi><mrow><mi>g</mi><mrow><mo>,</mo><mspace width="2px"></mspace></mrow><mn>1</mn></mrow></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>s</mi><mn>1</mn></msub></mrow><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤ÃÇ</mi><mrow><mi>g</mi><mrow><mo>,</mo><mspace width="2px"></mspace></mrow><mn>2</mn></mrow></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>s</mi><mn>2</mn></msub></mrow><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤ÃÇ</mi><mrow><mi>g</mi><mrow><mo>,</mo><mspace width="2px"></mspace></mrow><mn>3</mn></mrow></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>s</mi><mn>3</mn></msub></mrow><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mi>u</mi></mrow></mrow></math><figcaption>Model without dummy</figcaption></figure></div><blockquote>
          Note each variable here is a slope and if there is
          2 groups, then g can either be 1 or 2.
        </blockquote><div style="--fontsize-math-m: 14px;"><figure class="pre--horizontal-shadow"><math display="block"><mrow><msub><mi>H</mi><mn>0</mn></msub><mo>:</mo><mspace width="4px"></mspace><mrow><mrow><mo>{</mo><mrow><msub><mi>Œ≤</mi><mrow><mi>g</mi><mi>j</mi></mrow></msub><mo>:</mo><mspace width="4px"></mspace><mi>g</mi><mo>‚àà</mo><mrow><mo>{</mo><mn>1</mn><mo>,</mo><mspace width="4px"></mspace><mn>2</mn><mo>,</mo><mspace width="4px"></mspace><mo>‚ãØ</mo><mo>,</mo><mspace width="4px"></mspace><mi>G</mi><mo>}</mo></mrow></mrow><mo>}</mo></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><mo>{</mo><msub><mi>Œ≤</mi><mi>j</mi></msub><mo>}</mo></mrow></mrow><mspace width="4px"></mspace><mtext>for all</mtext><mspace width="4px"></mspace><mi>j</mi><mo>‚àà</mo><mrow><mo>{</mo><mn>0</mn><mo>,</mo><mspace width="4px"></mspace><mn>1</mn><mo>,</mo><mspace width="4px"></mspace><mn>2</mn><mo>,</mo><mspace width="4px"></mspace><mo>‚ãØ</mo><mo>,</mo><mspace width="4px"></mspace><mi>k</mi><mo>}</mo></mrow></mrow></math><figcaption>Chow test null hypothesis</figcaption></figure></div><p>
          Our null hypothesis basically claims that there is
          no difference for the slopes between the different
          tests. And we create this F statitic to test it
          which we also call the Chow Statitic. The null
          hypothesis implies the error variance between
          the groups must be equal.
        </p><figure class="pre--horizontal-shadow"><math display="block"><mrow><mi>F</mi><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><mfrac><mrow><mo>[</mo><msub><mtext>SSR</mtext><mi>P</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mrow><mo>(</mo><msub><mtext>SSR</mtext><mn>1</mn></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><msub><mtext>SSR</mtext><mn>2</mn></msub><mo>)</mo></mrow><mo>]</mo></mrow><mrow><mo>(</mo><msub><mtext>SSR</mtext><mn>1</mn></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><msub><mtext>SSR</mtext><mn>2</mn></msub><mo>)</mo></mrow></mfrac><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mfrac><mrow><mo>[</mo><mi>n</mi><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mrow><mn>2</mn><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mrow><mo>(</mo><mi>k</mi><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mn>1</mn><mo>)</mo></mrow></mrow><mo>]</mo></mrow><mrow><mo>(</mo><mi>k</mi><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mn>1</mn><mo>)</mo></mrow></mfrac></mrow></mrow></math><figcaption>Chow statistic</figcaption></figure><blockquote>
          SSR‚ÇÅ refers to the SSR of group one, and of
          course SSR‚ÇÇ is the same for group two. And
          SSR<sub>p</sub> is the <u>pooled</u>
          model with all groups.
        </blockquote><h4>Sum-of-square-residuals F Statistic</h4><p>
          The Chow test  only allows for null hypothesis that assume no
          difference between group. This includes the intercept! All it
          would take is a different intercept to reject that test which
          isn't very interesting, and we're actually more interested in
          whether there are different slopes between  groups. Again this
          is why the SSR F Stat exists.
        </p><math display="block"><mrow><mi>F</mi><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><mfrac><mrow><mo>[</mo><msub><mtext>SSR</mtext><mi>P</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mrow><mo>(</mo><msub><mtext>SSR</mtext><mn>1</mn></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><msub><mtext>SSR</mtext><mn>2</mn></msub><mo>)</mo></mrow><mo>]</mo></mrow><mrow><mo>(</mo><msub><mtext>SSR</mtext><mn>1</mn></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><msub><mtext>SSR</mtext><mn>2</mn></msub><mo>)</mo></mrow></mfrac><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mfrac><mrow><mo>[</mo><mi>n</mi><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mrow><mn>2</mn><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mrow><mo>(</mo><mi>k</mi><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mn>1</mn><mo>)</mo></mrow></mrow><mo>]</mo></mrow><mi>k</mi></mfrac></mrow></mrow></math><p>
          Note that k+1 has now become k, this is because we are not
          longer testing the intercept.
        </p></div><div class="container pre--container"><dl><dt>Difference in slope</dt><dd>
            This similar but different to shifting the intercept.
            It's more of a change in multiplier for the same
            quantative explanatory variable.
          </dd><dt>Restricted R Squared</dt><dd>
            When you're performing an F test, you're typically
            testing if an 2 or more added variables improves
            the model or not.
          </dd></dl><aside class="infobox"><h3 class="infobox-name">üí° SE's on dummy slope interactions</h3><div class="infobox-body"><div class="container"><p>
            Don't be alarmed if you see <strong>much larger standard
            errors</strong> for coefficents for interactions between a slope
            and a dummy compared to the slope in isolation, for
            interaction variables. An F test is better suited to help
            determine if these are statitically significant.
          </p></div></div></aside><aside class="infobox"><h3 class="infobox-name">üí° Chow Test Degree of Freedom</h3><div class="infobox-body"><div class="container"><p>
            Now that we are running seperate models for each
            group we techincally have omitted some variables
            from the regression (at least in the context of
            these being restricted models). So the degreees
            of freedom for these group specific regressions
            will be something like:
          </p><math display="block"><mrow><mi>n</mi><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mrow><mi>g</mi><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mrow><mo>(</mo><mi>k</mi><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mn>1</mn><mo>)</mo></mrow></mrow></mrow></math></div></div></aside><dl style="--fontsize-math-m: 12px;"><dt>RSS<sub>p</sub></dt><dd>
            Restricted Sum of Squares. It's not immediately
            obvious why this is considered a restricted model
            seeing as it includes all the results. But it
            is considered restricted before it forces all
            groups to share the same coefficients.
            <br>
            <br>
            I can't help but feel there has to be a better
            way to describe this.
          </dd><dt>RSS<sub>ur</sub></dt><dd>
            This is the sum of all grouped
            SSRs, something like:
            <br>
            <br>
            <math display="block"><mrow><msub><mi>SSR</mi><mi>ur</mi></msub><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><msub><mi>SSR</mi><mn>1</mn></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><msub><mi>SSR</mi><mn>2</mn></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mo>‚ãØ</mo><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><msub><mi>SSR</mi><mi>g</mi></msub></mrow></mrow></math>
          </dd></dl><aside class="infobox"><h3 class="infobox-name">üí° A Limitation of Chow Test</h3><div class="infobox-body"><div class="container"><p>
            One annoying restriction of the Chow test is
            that the null hypothesis is only allowed to
            assume there is no difference between the
            difference groups.
          </p></div></div></aside><dl style="--fontsize-math-m: 12px;"><dt>SSR F statistic</dt><dd>
            <p class="text-large" style="color: var(--fg-white-on-red); background: var(--bg-red); padding: 8px;"><strong>PLACEHOLDER</strong>: write meaning</p>
          </dd></dl></div></div></div></div>"
`;

exports[`app(unsw::2206::05.1).widgets > dummyVariablesForMultiCategories 1`] = `
"<div class="container pre--container"><h2>Using Dummy Variables for Multiple Categories</h2><div class="container dashbox" style="padding: 16px; border: var(--border-white-dash);"><div class="c2 twoThree pre--c2 pre--two-three"><div class="container pre--container"><ul class="no-item-padding" style="margin-block: 0px;"><li>Say you have a model with 2 variables, <strong>gender</strong> and <strong>married</strong>.<ul style="margin-block: 0px;"><li>If you have a coefficient for married, can you assume it's the same for both genders?</li><li>One thing you can do is have a seperate variable for each permutation of these categories<ul class="no-item-padding" style="margin-block: 0px;"><li>And then you omit one of the permutations (like single men)</li></ul></li><li>Another approach is to omit the intercept coefficent for each dummy<ol class="no-item-padding" style="margin-block: 0px;"><li>1st drawback of this is it more cumbersome to test for differences relative to a base group.</li><li>2nd drawback is some statitcal packages change how R-Squared is computed.</li></ol></li></ul></li></ul></div><dl><dt>Uncentererd R-Squared R‚ÇÄ¬≤</dt><dd>
          The R squared computed when the intercept is omitted.
          It is rarely suitable as a goodness of fit measure.
        </dd><dt>Ordinal Variable</dt><dd>This is categorical information with a meaningful ordering.</dd></dl></div><div class="container pre--container"><div style="display: grid; grid-template-columns: 1fr auto;"><h4>Ordinal data as Dummy Variables</h4><span style="display: grid; grid-auto-flow: column; align-items: center; max-height: 2em; line-height: 1; font-size: 10px; color: var(--fg-black-on-pink); background: var(--bg-pink); padding: 4px;"><strong>Book (C7 P230)</strong></span></div><ul class="no-item-padding" style="margin-block: 0px;"><li>
          Ordinal variables, such as a rating out of 1-5 may not make sense
          especaully if there are discrete criterias for movement between
          each value. Such as a credit score, which might reserve certain
          events to move to more extreme values.
        </li></ul><p class="text-large" style="color: var(--fg-white-on-red); background: var(--bg-red); padding: 8px;"><strong>PLACEHOLDER</strong>: write something about testing</p></div></div></div>"
`;

exports[`app(unsw::2206::05.1).widgets > interpretingRegressionResults 1`] = `"<div class="container pre--container"><h2>Interpreting Regression Results with Discrete Dependent Variables</h2><div class="container dashbox" style="padding: 16px; border: var(--border-white-dash);"><p class="text-large" style="color: var(--fg-white-on-red); background: var(--bg-red); padding: 8px;"><strong>PLACEHOLDER</strong>: content</p></div></div>"`;

exports[`app(unsw::2206::05.1).widgets > intro 1`] = `
"<div class="container pre--container"><div class="c2 twoThree pre--c2 pre--two-three"><div class="container pre--container"><h1>Multiple Regression Analysis with Qualitative Info<br><small style="color: rgb(170, 170, 255);">ECON2206, W5, Lecture 1</small></h1></div><aside class="infobox"><h3 class="infobox-name">üí° Resources</h3><div class="infobox-body"><div class="container"><ul class="no-item-padding" style="margin-block: 0px;"><li>Chapter 7</li></ul></div></div></aside></div><div style="display: grid; grid-template-columns: 1fr auto;"><h2>Introduction</h2><span style="display: grid; grid-auto-flow: column; align-items: center; max-height: 2em; line-height: 1; font-size: 10px; color: var(--fg-black-on-pink); background: var(--bg-pink); padding: 4px;"><strong>Book (C7 P220)</strong></span></div><div class="container dashbox" style="padding: 16px; border: var(--border-white-dash);"><ul style="margin-block: 0px;"><li>
        The purpose of this section is to provide a comprehensive analysis of
        how to include qualitative factors into regression models
      </li><li>
        The <strong>linear probability model</strong> (LPM) will be introduced which is a
        variant of multiple regression, where the coefficients can be
        interpreted as changes in a probability.
      </li><li>
        The simplicity of the LPM makes it useful in many empirical contexts,
        although it appears to be maligned by some econometricians.
      </li></ul></div></div>"
`;

exports[`app(unsw::2206::05.1).widgets > policyAnalysis 1`] = `"<div class="container pre--container"><h2>More on Policy Analysis and Program Evaluation</h2><div class="container dashbox" style="padding: 16px; border: var(--border-white-dash);"><p class="text-large" style="color: var(--fg-white-on-red); background: var(--bg-red); padding: 8px;"><strong>PLACEHOLDER</strong>: content</p></div></div>"`;
