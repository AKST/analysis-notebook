// Vitest Snapshot v1, https://vitest.dev/guide/snapshot.html

exports[`app(unsw::2206::01.2).widgets > assumptionsOfUnbiasednessInOLS 1`] = `
"<div class="container dashbox" style="padding: 16px; border: var(--border-white-dash);"><div class="container pre--container"><h2>Assumptions of Unbiasednesss of OLS</h2><p>
      These are also called the <strong>Gauss Markov Assumptions</strong>
      they can vary between multiple linear regression. But in order
      for the model to be unbiased these assumptions must be true.
      You can also think of these as a check list to evaluate the
      biasness of a model.
    </p></div><div class="c2 pre--c2"><div class="container pre--container"><h4>SLR 1 - Linear in Parameters</h4><p>
        Within population model the dependent variable y
        is related to the independent variable in a linear
        fashion.
      </p></div><div class="container pre--container"><h4>SLR 2 - Random Sampling</h4><p>We have a random sample of the population.</p></div></div><div class="c2 pre--c2"><div class="container pre--container"><h4>SLR 3 - Sample Variation</h4><p>Within the sample, there is more than one value for a variable</p><figure class="pre--horizontal-shadow"><math display="block"><mrow><mtext>Range</mtext><mspace width="2px"></mspace><mrow><mo>(</mo><mrow><mo>{</mo><msub><mi>x</mi><mi>i</mi></msub><mo>:</mo><mspace width="4px"></mspace><mrow><mi>i</mi><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mn>1</mn><mo>‚Ä¶</mo><mi>n</mi></mrow><mo>}</mo></mrow><mo>)</mo></mrow></mrow><mspace width="4px"></mspace><mo>&gt;</mo><mspace width="4px"></mspace><mn>0</mn></math><figcaption>SLR 3</figcaption></figure></div><div class="container pre--container"><h4>SLR 4 - Zero Conditional Mean</h4><p>The error has an expected value of zero for any given explanatory variable</p><figure class="pre--horizontal-shadow"><math display="block"><mrow><mrow><mi>E</mi><mspace width="2px"></mspace><mrow><mo>(</mo><mrow><mi>u</mi><mspace width="2px"></mspace><mo>|</mo><mspace width="2px"></mspace><mi>x</mi></mrow><mo>)</mo></mrow></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mn>0</mn></mrow></math><figcaption>SLR 4</figcaption></figure></div></div><div class="container pre--container"><h4>SLR 5 - Homoskedasticity</h4><p>
      The error u has the same variance given any value of
      the explanatory variable. Meaning at any point along
      the line of best fit variance is identical for the
      error rate.
    </p><figure class="pre--horizontal-shadow"><math display="block"><mrow><mrow><mtext>Var</mtext><mspace width="2px"></mspace><mrow><mo>(</mo><mrow><mi>u</mi><mspace width="2px"></mspace><mo>|</mo><mspace width="2px"></mspace><mi>x</mi></mrow><mo>)</mo></mrow></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mi>x</mi></mrow></math><figcaption>SLR 5</figcaption></figure></div><div class="container pre--container"><h3>Theorum for unbiassness of the OLS</h3><p class="text-large" style="color: var(--fg-white-on-red); background: var(--bg-red); padding: 8px;"><strong>PLACEHOLDER</strong>: READ page 43</p></div><div class="container pre--container"><h3>Analysis of Simple Linear Regression</h3><p class="text-large" style="color: var(--fg-white-on-red); background: var(--bg-red); padding: 8px;"><strong>PLACEHOLDER</strong>: Explain how this is useful and important</p><div class="c2 pre--c2"><figure class="pre--horizontal-shadow"><math display="block"><mrow><mrow><mtext>Var</mtext><mspace width="2px"></mspace><mrow><mo>(</mo><msub><mi>Œ≤ÃÇ</mi><mn>1</mn></msub><mo>)</mo></mrow></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mfrac><msup><mi>œÉ</mi><mn>2</mn></msup><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><msup><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mi>xÃÑ</mi><mo>)</mo></mrow><mn>2</mn></msup></mrow></mrow></mfrac><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mfrac><msup><mi>œÉ</mi><mn>2</mn></msup><msub><mi>SST</mi><mi>x</mi></msub></mfrac></mrow></math><figcaption>Constraint A, Sampling variance of estimators</figcaption></figure><figure class="pre--horizontal-shadow"><math display="block"><mrow><mrow><mtext>Var</mtext><mspace width="2px"></mspace><mrow><mo>(</mo><msub><mi>Œ≤ÃÇ</mi><mn>1</mn></msub><mo>)</mo></mrow></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mfrac><mrow><msup><mi>œÉ</mi><mn>2</mn></msup><msup><mi>n</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><msubsup><mi>x</mi><mi>i</mi><mn>2</mn></msubsup></mrow></mrow></mrow><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><msup><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mi>xÃÑ</mi><mo>)</mo></mrow><mn>2</mn></msup></mrow></mrow></mfrac></mrow></math><figcaption>Constraint B, Sampling variance of estimators</figcaption></figure></div><figure class="pre--horizontal-shadow"><math display="block"><mtable><mtr columnalign="right center left center left"><mtd columnalign="right"><mrow><mtext>Var</mtext><mspace width="2px"></mspace><mrow><mo>(</mo><msub><mi>Œ≤ÃÇ</mi><mn>1</mn></msub><mo>)</mo></mrow></mrow></mtd><mtd columnalign="center"><mo>=</mo></mtd><mtd columnalign="left"><mrow><msup><mrow><mo>(</mo><msup><msub><mi>SST</mi><mi>x</mi></msub><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>)</mo></mrow><mn>2</mn></msup><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mrow><mtext>Var</mtext><mspace width="2px"></mspace><mrow><mo>(</mo><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><mrow><msub><mi>u</mi><mi>i</mi></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mi>xÃÑ</mi><mo>)</mo></mrow></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mtd><mtd columnalign="center"><mo>=</mo></mtd><mtd columnalign="left"><mrow><msup><mrow><mo>(</mo><msup><msub><mi>SST</mi><mi>x</mi></msub><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>)</mo></mrow><mn>2</mn></msup><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mrow><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><msup><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mi>xÃÑ</mi><mo>)</mo></mrow><mn>2</mn></msup></mrow></mrow><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mrow><mtext>Var</mtext><mspace width="2px"></mspace><mrow><mo>(</mo><msub><mi>u</mi><mi>i</mi></msub><mo>)</mo></mrow></mrow></mrow></mrow></mtd></mtr><mtr columnalign="right center left center left"><mtd columnalign="right"><mrow></mrow></mtd><mtd columnalign="center"><mo>=</mo></mtd><mtd columnalign="left"><mrow><msup><mrow><mo>(</mo><msup><msub><mi>SST</mi><mi>x</mi></msub><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>)</mo></mrow><mn>2</mn></msup><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><msup><mi>œÉ</mi><mn>2</mn></msup><msup><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mi>xÃÑ</mi><mo>)</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow></mtd><mtd columnalign="center"><mo>=</mo></mtd><mtd columnalign="left"><mrow></mrow></mtd></mtr><mtr columnalign="right center left center left"><mtd columnalign="right"><mrow></mrow></mtd><mtd columnalign="center"><mo>=</mo></mtd><mtd columnalign="left"><mrow><mrow><msup><mi>œÉ</mi><mn>2</mn></msup><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msup><mrow><mo>(</mo><msup><msub><mi>SST</mi><mi>x</mi></msub><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>)</mo></mrow><mn>2</mn></msup><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><msup><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mi>xÃÑ</mi><mo>)</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow></mrow></mtd><mtd columnalign="center"><mo>=</mo></mtd><mtd columnalign="left"><mrow><mrow><mrow><msup><mi>œÉ</mi><mn>2</mn></msup><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msup><mrow><mo>(</mo><msup><msub><mi>SST</mi><mi>x</mi></msub><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>)</mo></mrow><mn>2</mn></msup><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>SST</mi><mi>x</mi></msub></mrow></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mfrac><msup><mi>œÉ</mi><mn>2</mn></msup><msub><mi>SST</mi><mi>x</mi></msub></mfrac></mrow></mtd></mtr></mtable></math><figcaption>Given the above assumptions this should hold</figcaption></figure></div></div>"
`;

exports[`app(unsw::2206::01.2).widgets > functionalFormsInvolvingLogs 1`] = `
"<div class="container pre--container"><div class="container dashbox" style="padding: 16px; border: var(--border-white-dash);"><h2>Functional Forms Involving Logs</h2><p>
      Linear regression is linear in the sense it is linear in
      parameters (unforunately I don't know what that means), and
      more simply that can be put there is a linear relation between
      the either side of the regression. This isn't to say you can't
      represent nonlinear relations.
    </p><p>
      If you have a relation between the logarithm of your
      dependent variable with independent variable or vice versa
      you can simply create a new variable for that logarithm
      and use it in computing your coefficents. Same goes for
      exponents or anything else of that nature. See the table
      below for some names of common functional forms.
    </p><ul class="no-item-padding" style="margin-block: 0px;"><li>log level is sometimes called semi-elasticity</li><li>log log is the elasticity of y with respect to x</li><li>However I am unsure if there are other names for the rest</li></ul></div><div class="c2 pre--c2"><table><thead><tr><th>Model</th><th>Dependent Var</th></tr></thead><tbody><tr><td>Level-Level</td><td>y</td></tr><tr><td>Level-Log</td><td>y</td></tr><tr><td>Log-Level</td><td>log(y)</td></tr><tr><td>Log-Log</td><td>log(y)</td></tr></tbody></table><table><thead><tr><th>Independent Var</th><th>Interpreation of Œ≤ÃÇ‚ÇÅ</th></tr></thead><tbody><tr><td>x</td><td>Œîy = Œ≤‚ÇÅ Œîx</td></tr><tr><td>log(x)</td><td>Œîy = (Œ≤‚ÇÅ/100) %Œîx</td></tr><tr><td>x</td><td>%Œîy = (100Œ≤‚ÇÅ) Œîx</td></tr><tr><td>log(x)</td><td>%Œîy = Œ≤‚ÇÅ %Œîx</td></tr></tbody></table></div></div>"
`;

exports[`app(unsw::2206::01.2).widgets > intro 1`] = `
"<div class="container pre--container"><div class="c2 twoThree pre--c2 pre--two-three"><div class="container pre--container"><h1>Simple Regression Model<br><small style="color: rgb(170, 170, 255);">ECON2206, W1, Lecture 2</small></h1><p>
        To start with analysing cross sectional data we are
        going to look at simple regression models.
      </p></div><aside class="infobox"><h3 class="infobox-name">üí° Resources</h3><div class="infobox-body"><div class="container"><ul class="no-item-padding" style="margin-block: 0px;"><li>See chapter 2 of the textbook.</li><li><a href="https://www.princeton.edu/~otorres/Regression101.pdf">Linear Regression in Stata</a></li></ul></div></div></aside></div></div>"
`;

exports[`app(unsw::2206::01.2).widgets > linearRegression 1`] = `
"<div class="container dashbox" style="padding: 16px; border: var(--border-white-dash);"><h2>Linear Regression</h2><h3>Terminology</h3><div class="c2 twoThree pre--c2 pre--two-three"><div class="container pre--container"><figure class="pre--horizontal-shadow"><math display="block"><mrow><mi>y</mi><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤</mi><mn>0</mn></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><msub><mi>Œ≤</mi><mn>1</mn></msub><mi>x</mi><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mi>u</mi></mrow></mrow></math><figcaption>Simple Linear regression</figcaption></figure><p><strong>u</strong>
        is sometimes called the erro term of distubance in
        the relationship, representing factors other than
        x that affect y. You can also simply think of it as <strong>unobserved</strong>.
      </p></div><table><thead><tr><th>Y</th><th>X</th></tr></thead><tbody><tr><td>Dependent variable</td><td>Independent variable</td></tr><tr><td>Explained variable</td><td>Explanatory variable</td></tr><tr><td>Response variable</td><td>Control variable</td></tr><tr><td>Predicted variable</td><td>Predictor variable</td></tr><tr><td>Regressand variable</td><td>Regressor variable</td></tr></tbody></table></div><h3>Population Assumptions and Definitions</h3><div class="c2 pre--c2"><div class="container pre--container"><h4>Linear Effect of X on Y</h4><figure class="pre--horizontal-shadow"><math display="block"><mrow><mi>ùõ•</mi><mi>y</mi><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><msub><mi>Œ≤</mi><mn>1</mn></msub><mi>ùõ•</mi><mi>x</mi></mrow><mspace width="16px"></mspace><mtext>if</mtext><mspace width="16px"></mspace><mrow><mi>ùõ•</mi><mi>u</mi><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mn>0</mn></mrow></math><figcaption>Linear effect requirement</figcaption></figure><p>
        Given the above is derived from the regression with Œ≤‚ÇÄ, we should
        see a zero change in u with an increase in x, this also means Œ≤‚ÇÅ
        is the <strong>slope</strong> of the relationship between x and y.
      </p></div><div class="container pre--container"><h4>Average value of u</h4><figure class="pre--horizontal-shadow"><math display="block"><mrow><mrow><mi>E</mi><mspace width="2px"></mspace><mrow><mo>(</mo><mi>u</mi><mo>)</mo></mrow></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mn>0</mn></mrow></math><figcaption>Average u in the population given Œ≤‚ÇÄ</figcaption></figure><p>
        One assumption we need to make before we assume how x and u
        relate to one another is that for our model the average u
        in the population should be zero.
      </p></div></div><div class="container pre--container"><h4>Average U does not depent on X</h4><figure class="pre--horizontal-shadow"><math display="block"><mrow><mrow><mi>E</mi><mspace width="2px"></mspace><mrow><mo>(</mo><mrow><mi>u</mi><mspace width="2px"></mspace><mo>|</mo><mspace width="2px"></mspace><mi>x</mi></mrow><mo>)</mo></mrow></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><mi>E</mi><mspace width="2px"></mspace><mrow><mo>(</mo><mi>u</mi><mo>)</mo></mrow></mrow></mrow></math><figcaption>Assume U does not depend on X</figcaption></figure><p>
      This says that the average <strong>u</strong> across the
      population determined by x is equal to the average <strong>u</strong>
      over the population. Put another way, this says that u is <strong>mean independent</strong> of x. Combining this with E(u) = 0,
      we get the zero conditional mean assumption.
    </p><figure class="pre--horizontal-shadow"><math display="block"><mrow><mrow><mi>E</mi><mspace width="2px"></mspace><mrow><mo>(</mo><mrow><mi>u</mi><mspace width="2px"></mspace><mo>|</mo><mspace width="2px"></mspace><mi>x</mi></mrow><mo>)</mo></mrow></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mn>0</mn></mrow></math><figcaption>Zero Conditional mean assumption</figcaption></figure></div><hr><div class="container pre--container"><h4>Population regression function (PRF)</h4><div class="grid-responsive-row pre--grid-responsive-row" style="--grid-responsive-row-slim-columns: 1fr; --grid-responsive-row-mobile-columns: 1fr; --grid-responsive-row-desktop-columns: 2fr 2fr 3fr;"><figure class="pre--horizontal-shadow"><math display="block"><mrow><mrow><mi>E</mi><mspace width="2px"></mspace><mrow><mo>(</mo><mrow><mi>y</mi><mspace width="2px"></mspace><mo>|</mo><mspace width="2px"></mspace><mi>x</mi></mrow><mo>)</mo></mrow></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤</mi><mn>0</mn></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mi>x</mi></mrow></mrow></mrow></math><figcaption>The PRF</figcaption></figure><figure class="pre--horizontal-shadow"><math display="block"><mrow><msub><mi>y</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤</mi><mn>0</mn></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>x</mi><mi>i</mi></msub></mrow><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><msub><mi>u</mi><mi>i</mi></msub></mrow></mrow></math><figcaption>Also the PRF</figcaption></figure><aside class="infobox"><h3 class="infobox-name">üí° Population Parameters</h3><div class="infobox-body"><div class="container"><p>
      Œ≤‚ÇÄ and Œ≤‚ÇÅ of the population are referred to as
      population parameters. They are unknown in
      reality.
    </p></div></div></aside></div><p>
      The right hand side does not mean, y = [right hand side]. It is
      more accurate to read it as a one input increase in x changes the
      expected value by the amount of Œ≤‚ÇÅ. So if you collected all observations
      of Y and X where Y was the same value, you'd see a normal distribution
      for all the values of X where the average value was (Y - Œ≤‚ÇÄ) √∑ Œ≤‚ÇÅ.
      Given this we can break the regression down into 2 components:
    </p><ul class="no-item-padding" style="margin-block: 0px;"><li><strong>Systematic part of y</strong>: E(y|x) or Œ≤‚ÇÄ + Œ≤‚ÇÅx</li><li><strong>Unsystematic part of y</strong>: u, or the part y not explained by x</li></ul><p>In reality we will never know the actual PRF in most meaningful cases.</p></div></div>"
`;

exports[`app(unsw::2206::01.2).widgets > models 1`] = `
"<div class="container dashbox" style="padding: 16px; border: var(--border-white-dash);"><h2>Modelling and understanding problems</h2><div class="c2 pre--c2"><div class="container pre--container"><h3>Theoretical Model</h3><p>
        When tackling economic problems or understanding the
        economic nature of a system (an economy, institution,
        industry, etc), or economic characteristic of a system
        and its partipants, it helps to start with an theoretical
        model in which modifications to the system can be thought
        through and quantitied.
      </p><p>
        In a way its an attempt to explain the nature of the economic
        system in terms of the thing in of itself, and it can be
        expressed in terms of properties that observable and unobservable.
        The problem of measuring these things will come later.
      </p></div><div class="container pre--container"><h3>Economic Models</h3><p>
        This can also be thought of an <strong>Econometric model</strong>
        and its when we start to concern ourselves with what we can
        and cannot measure. The goal is to map theory to what we can
        observe, and vice versa. Eventually to see where reality relates
        to these models, or if our models are actually representive of
        reality.
      </p><p>
        Given the focus on what we can measure, we only include
        what we can measure within the model. In a simple
        linear regression model, this is captured in the error term,
        so there are at least some way of accounting for these in
        relative terms to what we can observe. We call these <strong>unobservable variables</strong>.
      </p></div></div></div>"
`;

exports[`app(unsw::2206::01.2).widgets > ordinaryLeastSquaresEstimate 1`] = `
"<div class="container dashbox" style="padding: 16px; border: var(--border-white-dash);"><h2>Deriving the Ordinary Least Squares Estimates</h2><div class="c2 twoThree pre--c2 pre--two-three"><div class="container pre--container"><p>
        In order to estimate the Œ≤‚ÇÄ and Œ≤‚ÇÅ for the population we
        need to sample from the population which we can produce
        our estimates as Œ≤ÃÇ‚ÇÄ and Œ≤ÃÇ‚ÇÅ. Given a sample of size <strong>n</strong> each the X, Y &amp; U for each observation is
        specified in the linear regression like so.
      </p><figure class="pre--horizontal-shadow"><math display="block"><mrow><msub><mi>y</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤</mi><mn>0</mn></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>x</mi><mi>i</mi></msub></mrow><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><msub><mi>u</mi><mi>i</mi></msub></mrow></mrow></math><figcaption>Sample linear regression</figcaption></figure><p>
        For each observation u·µ¢ is the information explaining
        y·µ¢ not captured in x·µ¢. It is also called the <strong>error term</strong>.
      </p><figure class="pre--horizontal-shadow"><div class="container pre--container"><p><math display="block"><mrow><mrow><mi>E</mi><mspace width="2px"></mspace><mrow><mo>(</mo><mrow><mi>y</mi><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><msub><mi>Œ≤</mi><mn>0</mn></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mi>x</mi></mrow></mrow><mo>)</mo></mrow></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mn>0</mn></mrow></math></p><p><math display="block"><mrow><mrow><mi>E</mi><mrow><mo>[</mo><mi>x</mi><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mrow><mo>(</mo><mrow><mi>y</mi><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><msub><mi>Œ≤</mi><mn>0</mn></msub></mrow><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mi>x</mi></mrow><mo>)</mo></mrow><mo>]</mo></mrow></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mn>0</mn></mrow></math></p></div><figcaption>Joint Probability distribution of x &amp; y with Œ≤‚ÇÄ and Œ≤‚ÇÅ</figcaption></figure><p>
        It is helpful to think of the above of contraints in which we
        can count on solving for the values of Œ≤‚ÇÄ and Œ≤‚ÇÅ for the population.
        However in order to get estimates of the population from a sample
        we use <strong>Sum of first order conditions</strong>.
      </p></div><div class="container pre--container"><aside class="infobox"><h3 class="infobox-name">üí° Note on Index Syntax</h3><div class="infobox-body"><div class="container"><p>
      While subscript 1 &amp; 0 are used for the coefficents
      of a linear regression, when used on variables it is
      in reference to an observation in a sample. It is
      often generalised as an i, as in <em>x·µ¢</em>
      for the x of the postion i where i is a number between
      1 and n (sometimes this can be 0 &amp; n-1).
    </p><math display="block"><mrow><mtext>Let</mtext><mspace width="8px"></mspace><mrow><mo>{</mo><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>y</mi><mi>i</mi></msub><mo>)</mo></mrow><mo>:</mo><mspace width="8px"></mspace><mn>1</mn><mo>,</mo><mspace width="4px"></mspace><mo>‚Ä¶</mo><mo>,</mo><mspace width="4px"></mspace><mi>n</mi><mo>}</mo></mrow></mrow></math></div></div></aside><h4>Platonic properties of unobserved</h4><figure class="pre--horizontal-shadow"><math display="block"><mrow><mrow><mi>E</mi><mspace width="2px"></mspace><mrow><mo>(</mo><mi>u</mi><mo>)</mo></mrow></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mn>0</mn></mrow></math><figcaption>mean unobserved is zero</figcaption></figure><figure class="pre--horizontal-shadow"><math display="block"><mrow><mrow><mtext>Covar</mtext><mspace width="2px"></mspace><mrow><mo>(</mo><mi>x</mi><mo>,</mo><mspace width="4px"></mspace><mi>u</mi><mo>)</mo></mrow></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><mi>E</mi><mspace width="2px"></mspace><mrow><mo>(</mo><mi>xu</mi><mo>)</mo></mrow></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mn>0</mn></mrow></math><figcaption>covariance between u &amp; x is zero</figcaption></figure></div></div><h4>Sum of First order condtiions</h4><p>
    Using a method of moment approach we take the above population
    Joint distribution of x and y, assuming the properties of
    unobservables inrespect to x we derive these estimates allowing
    us to constrain our estimations for Œ≤‚ÇÄ and Œ≤‚ÇÅ.
  </p><figure class="pre--horizontal-shadow"><div class="c2 pre--c2"><math display="block"><mrow><msup><mi>n</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><mrow><mo>(</mo><mrow><msub><mi>y</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><msub><mi>Œ≤ÃÇ</mi><mn>0</mn></msub></mrow><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><msub><mi>Œ≤ÃÇ</mi><mn>1</mn></msub><msub><mi>x</mi><mi>i</mi></msub><mo>)</mo></mrow></mrow></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mn>0</mn></mrow></math><math display="block"><mrow><mrow><msup><mi>n</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><msub><mi>x</mi><mi>i</mi></msub><mrow><mo>(</mo><mrow><msub><mi>y</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><msub><mi>Œ≤ÃÇ</mi><mn>0</mn></msub></mrow><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤ÃÇ</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>x</mi><mi>i</mi></msub></mrow><mo>)</mo></mrow></mrow></mrow></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mn>0</mn></mrow></math></div><figcaption>Sample counterparts to population above joint probability constraints</figcaption></figure><div class="c2 twoThree pre--c2 pre--two-three"><div class="container pre--container"><h4>Estmating Œ≤ÃÇ‚ÇÄ</h4><p>
        While we still need to know the value of Œ≤ÃÇ‚ÇÅ before we can solve
        for Œ≤ÃÇ‚ÇÄ, using the properties summation we can rewrite the above
        to get the following to estimate Œ≤ÃÇ‚ÇÄ.
      </p><figure class="pre--horizontal-shadow"><div class="c2 pre--c2"><math display="block"><mrow><mi>yÃÑ</mi><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤ÃÇ</mi><mn>0</mn></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><msub><mi>Œ≤ÃÇ</mi><mn>1</mn></msub><mi>xÃÑ</mi></mrow></mrow></math><math display="block"><mrow><msub><mi>Œ≤ÃÇ</mi><mn>0</mn></msub><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><mi>yÃÑ</mi><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><msub><mi>Œ≤ÃÇ</mi><mn>1</mn></msub><mi>xÃÑ</mi></mrow></mrow></math></div><figcaption>Solving for Œ≤ÃÇ‚ÇÄ using properties of summation</figcaption></figure></div><aside class="infobox"><h3 class="infobox-name">üí° Properties of Summation</h3><div class="infobox-body"><div class="container"><p class="text-large" style="color: var(--fg-white-on-red); background: var(--bg-red); padding: 8px;"><strong>PLACEHOLDER</strong>: Write me later</p></div></div></aside></div><div class="container pre--container"><h4>Estmating Œ≤ÃÇ‚ÇÅ</h4><div class="c2 twoThree pre--c2 pre--two-three"><p>
        And continuing on from below we'll solve for Œ≤‚ÇÅ. We start by
        injecting our above definition of <strong>Œ≤ÃÇ‚ÇÄ</strong> into the <strong>Sum of first order conditions</strong>, and from there we'll
        seek to isolate Œ≤ÃÇ‚ÇÅ. The right hand equation (or subsequent) show
        the factoring undertaken before rearrive at our equation for Œ≤ÃÇ‚ÇÅ.
      </p><aside class="infobox"><h3 class="infobox-name">üí° Œ≤ÃÇ‚ÇÅ is a random variable</h3><div class="infobox-body"><div class="container"><p>
      Œ≤ÃÇ·µ¢ is a random variable, in that each time you
      generate a sample you draw a new value
    </p></div></div></aside></div><div class="c2 pre--c2"><figure class="pre--horizontal-shadow"><math display="block"><mtable><mtr columnalign=""><mtd columnalign=""><mtd><mrow><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><mrow><msub><mi>x</mi><mi>i</mi></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mrow><mo>[</mo><mrow><msub><mi>y</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mrow><mo>(</mo><mi>yÃÑ</mi><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤ÃÇ</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mi>xÃÑ</mi></mrow><mo>)</mo></mrow></mrow><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤ÃÇ</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>x</mi><mi>i</mi></msub></mrow><mo>]</mo></mrow></mrow></mrow></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mn>0</mn></mrow></mtd></mtd></mtr><mtr columnalign=""><mtd columnalign=""><mtd><mrow><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><mrow><msub><mi>x</mi><mi>i</mi></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mrow><mo>(</mo><msub><mi>y</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mi>yÃÑ</mi><mo>)</mo></mrow></mrow></mrow></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤ÃÇ</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><mrow><msub><mi>x</mi><mi>i</mi></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mi>xÃÑ</mi><mo>)</mo></mrow></mrow></mrow></mrow></mrow></mrow></mtd></mtd></mtr></mtable></math><figcaption>
        Start by plugging Œ≤ÃÇ‚ÇÄ into<br>
        the Sum of 1st Order Condition
      </figcaption></figure><figure class="pre--horizontal-shadow"><math display="block"><mtable><mtr columnalign=""><mtd columnalign=""><mtd><mrow><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><mrow><msub><mi>x</mi><mi>i</mi></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mi>xÃÑ</mi><mo>)</mo></mrow></mrow></mrow></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><msup><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mi>xÃÑ</mi><mo>)</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow></mtd></mtd></mtr><mtr columnalign=""><mtd columnalign=""><mtd><mrow><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><mrow><msub><mi>x</mi><mi>i</mi></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mrow><mo>(</mo><msub><mi>y</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mi>yÃÑ</mi><mo>)</mo></mrow></mrow></mrow></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><mrow><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mi>xÃÑ</mi><mo>)</mo></mrow><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mrow><mo>(</mo><msub><mi>y</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mi>yÃÑ</mi><mo>)</mo></mrow></mrow></mrow></mrow></mrow></mtd></mtd></mtr></mtable></math><figcaption>
        Before isolating for Œ≤ÃÇ‚ÇÅ note<br>
        how these can be rearranged
      </figcaption></figure></div><p>
      Given the sum of (x<sub>i</sub>-xÃÑ)¬≤ is greater than zero we
      compute Œ≤ÃÇ‚ÇÅ as shown, which can be further simplifed to be œÉÃÇ<sub>y</sub> divided by œÉÃÇ<sub>x</sub> times œÅÃÇ<sub>xy</sub> which is the correlation (Noting that œÉÃÇ is the
      sample standard deviation and œÅÃÇ is the sample correlation).
    </p><div class="grid-responsive-row pre--grid-responsive-row" style="--grid-responsive-row-slim-columns: 1fr; --grid-responsive-row-mobile-columns: 1fr; --grid-responsive-row-desktop-columns: auto auto auto auto;"><figure class="pre--horizontal-shadow"><math display="block"><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><mrow><msup><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mi>xÃÑ</mi><mo>)</mo></mrow><mn>2</mn></msup><mspace width="4px"></mspace><mo>&gt;</mo><mspace width="4px"></mspace><mn>0</mn></mrow></mrow></mrow></math><figcaption>Given</figcaption></figure><figure class="pre--horizontal-shadow"><math display="block"><mrow><msub><mi>Œ≤ÃÇ</mi><mn>1</mn></msub><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mfrac><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><mrow><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mi>xÃÑ</mi><mo>)</mo></mrow><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mrow><mo>(</mo><msub><mi>y</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mi>yÃÑ</mi><mo>)</mo></mrow></mrow></mrow></mrow><msup><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mi>xÃÑ</mi><mo>)</mo></mrow></mrow></mrow><mn>2</mn></msup></mfrac></mrow></math><figcaption>Estimating Œ≤ÃÇ‚ÇÅ, the OLS slope</figcaption></figure><figure class="pre--horizontal-shadow"><math display="block"><mrow><msub><mi>Œ≤ÃÇ</mi><mn>1</mn></msub><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><msub><mi>œÅÃÇ</mi><mrow><mi>x</mi><mi>y</mi></mrow></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mfrac><msub><mi>œÉÃÇ</mi><mi>x</mi></msub><msub><mi>œÉÃÇ</mi><mi>y</mi></msub></mfrac></mrow></mrow></math><figcaption>Simpified Œ≤ÃÇ‚ÇÅ</figcaption></figure><figure class="pre--horizontal-shadow"><math display="block"><mrow><msub><mi>Œ≤</mi><mn>1</mn></msub><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><msub><mi>œÅ</mi><mrow><mi>x</mi><mi>y</mi></mrow></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mfrac><msub><mi>œÉ</mi><mi>x</mi></msub><msub><mi>œÉ</mi><mi>y</mi></msub></mfrac></mrow></mrow></math><figcaption>Population Œ≤‚ÇÅ</figcaption></figure></div></div><div class="container pre--container"><h4>Sample Regression Function, Fitted values and residuals</h4><p>
      Using Œ≤ÃÇ‚ÇÄ with Œ≤ÃÇ‚ÇÅ times x·µ¢ we can get yÃÇ·µ¢ which is the
      <strong>fitted value</strong> of y, and the difference between
      the observed y·µ¢ and its fitted value yÃÇ·µ¢ is called the
      <strong>residual</strong> as uÃÇ·µ¢. Note this is actually different
      from the error term or unobserved.
    </p><div class="grid-responsive-row pre--grid-responsive-row" style="--grid-responsive-row-slim-columns: 1fr; --grid-responsive-row-mobile-columns: 1fr; --grid-responsive-row-desktop-columns: 1fr auto 1fr;"><figure class="pre--horizontal-shadow"><math display="block"><mrow><msub><mi>yÃÇ</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤ÃÇ</mi><mn>0</mn></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤ÃÇ</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>x</mi><mi>i</mi></msub></mrow></mrow></mrow></math><figcaption>Fitted value of yÃÇ·µ¢</figcaption></figure><figure class="pre--horizontal-shadow"><math display="block"><mrow><msub><mi>uÃÇ</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><msub><mi>y</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><msub><mi>yÃÇ</mi><mi>i</mi></msub></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><msub><mi>y</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤ÃÇ</mi><mn>0</mn></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤ÃÇ</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>x</mi><mi>i</mi></msub></mrow></mrow></mrow></mrow></math><figcaption>Computing residual uÃÇ·µ¢</figcaption></figure><figure class="pre--horizontal-shadow"><math display="block"><mrow><mi>yÃÇ</mi><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤ÃÇ</mi><mn>0</mn></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤ÃÇ</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mi>x</mi></mrow></mrow></mrow></math><figcaption>Sample Regression Function</figcaption></figure></div><p>
      We've estimated our coefficents Œ≤ÃÇ‚ÇÄ and Œ≤ÃÇ‚ÇÅ so that the average uÃÇ·µ¢
      is 0, and you can see that if you start back at the Sum of
      First Order conditions where the right hand side is 0 and the
      residuals are omitted from the left hand side. At least that's
      how I understand it (there may be more formal ways of
      demostrating that).
    </p></div><div class="container pre--container"><h4>SST, SSE, SSR and Goodness of Fit</h4><p>
      To measure <strong>goodness of fit</strong> we'll first define
      a few more concepts which we will use to compute <strong>R¬≤</strong>
      which is a way for assessing the overall fit of the data. They
      have been defined down below:
    </p><div class="grid-responsive-row pre--grid-responsive-row" style="--grid-responsive-row-slim-columns: 1fr; --grid-responsive-row-mobile-columns: 1fr; --grid-responsive-row-desktop-columns: auto auto auto;"><figure class="pre--horizontal-shadow"><math display="block"><mrow><mi>SST</mi><mspace width="4px"></mspace><mo>‚â°</mo><mspace width="4px"></mspace><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><msup><mrow><mo>(</mo><msub><mi>y</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mi>yÃÑ</mi><mo>)</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow></math><figcaption>Total Sum of Squares</figcaption></figure><figure class="pre--horizontal-shadow"><math display="block"><mrow><mi>SSE</mi><mspace width="4px"></mspace><mo>‚â°</mo><mspace width="4px"></mspace><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><msup><mrow><mo>(</mo><msub><mi>yÃÇ</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mi>yÃÑ</mi><mo>)</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow></math><figcaption>Explained Sum of Squares</figcaption></figure><figure class="pre--horizontal-shadow"><math display="block"><mrow><mi>SSR</mi><mspace width="4px"></mspace><mo>‚â°</mo><mspace width="4px"></mspace><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><msubsup><mi>uÃÇ</mi><mi>i</mi><mn>2</mn></msubsup></mrow></mrow></mrow></math><figcaption>Residual Sum of Squares</figcaption></figure></div><p>
      They all related to each other like as shown on the left, and
      you can use them like so compute the R-Squared which is sometimes
      called the Coefficient of determination. It is a measure of the
      portion of variance captured by the model.
    </p><div class="grid-responsive-row pre--grid-responsive-row" style="--grid-responsive-row-slim-columns: 1fr; --grid-responsive-row-mobile-columns: 1fr; --grid-responsive-row-desktop-columns: auto auto;"><figure class="pre--horizontal-shadow"><math display="block"><mrow><mi>SST</mi><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><mi>SSE</mi><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mi>SSR</mi></mrow></mrow></math><figcaption>Sum of Squares constraint</figcaption></figure><figure class="pre--horizontal-shadow"><math display="block"><mrow><msup><mi>R</mi><mn>2</mn></msup><mspace width="4px"></mspace><mo>‚â°</mo><mspace width="4px"></mspace><mrow><mfrac><mi>SSE</mi><mi>SST</mi></mfrac><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><mn>1</mn><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mfrac><mi>SSR</mi><mi>SST</mi></mfrac></mrow></mrow></mrow></math><figcaption>R Squared</figcaption></figure></div><figure class="pre--horizontal-shadow"><math display="block"><mrow><msup><mi>R</mi><mn>2</mn></msup><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mfrac><msup><mrow><mo>(</mo><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><mrow><mo>(</mo><msub><mi>y</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mi>yÃÑ</mi><mo>)</mo></mrow><mrow><mo>(</mo><msub><mi>≈∑</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mi>≈∑ÃÑ</mi><mo>)</mo></mrow></mrow></mrow><mo>)</mo></mrow><mn>2</mn></msup><mrow><mrow><mo>(</mo><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><msup><mrow><mo>(</mo><msub><mi>y</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mi>yÃÑ</mi><mo>)</mo></mrow><mn>2</mn></msup></mrow></mrow><mo>)</mo></mrow><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><mrow><mo>(</mo><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><msup><mrow><mo>(</mo><msub><mi>≈∑</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mi>≈∑ÃÑ</mi><mo>)</mo></mrow><mn>2</mn></msup></mrow></mrow><mo>)</mo></mrow></mrow></mfrac></mrow></math><figcaption>R Square Expanded</figcaption></figure></div><div class="container pre--container"><h4>What is Ordinary Least Squares really?</h4><p>
      To be honest, I am still wrapping my head around
      this, but for the best answer I can give is, it
      solves for Œ≤ÃÇ‚ÇÄ and Œ≤ÃÇ‚ÇÅ so that you have the smallest
      value possible.
    </p><figure class="pre--horizontal-shadow"><math display="block"><mrow><mrow><mtext>min</mtext><mspace width="4px"></mspace><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><msubsup><mi>uÃÇ</mi><mi>i</mi><mn>2</mn></msubsup></mrow></mrow></mrow><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mtext>min</mtext><mspace width="4px"></mspace><mo>=</mo><mspace width="4px"></mspace><mrow><munderover><mi>‚àë</mi><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mspace width="4px"></mspace><mrow><msup><mrow><mo>[</mo><msub><mi>y</mi><mi>i</mi></msub><mspace width="4px"></mspace><mo>-</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤</mi><mn>0</mn></msub><mspace width="4px"></mspace><mo>+</mo><mspace width="4px"></mspace><mrow><msub><mi>Œ≤</mi><mn>1</mn></msub><mspace width="1px"></mspace><mo>‚Å¢</mo><mspace width="1px"></mspace><msub><mi>x</mi><mi>i</mi></msub></mrow></mrow><mo>]</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow></math><figcaption>Minimisation constraint</figcaption></figure></div></div>"
`;

exports[`app(unsw::2206::01.2).widgets > summary 1`] = `"<div class="container dashbox" style="padding: 16px; border: var(--border-white-dash);"><h2>Conclusion</h2><p>main points are...</p><p style="color: var(--fg-white-on-blue); background: var(--bg-blue); padding: 8px;"><p><strong>NOTE</strong><ul class="no-item-padding" style="margin-block: 0px;"><li>Population regression</li><li>Sample regression</li><li>Estimation</li><li>Fitted values</li><li>Regression risduals</li><li>Understand why estimated parameteres are (ex-ante) random variables</li></ul></p></p></div>"`;
